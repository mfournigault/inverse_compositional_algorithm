{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook for testing the algorithms under Google colab\n",
        "\n",
        "## 1. Introduction\n",
        "The algorithms are defined in the publication:\n",
        "    Javier Sánchez, The Inverse Compositional Algorithm for Parametric Registration, Image Processing On Line, 6 (2016), pp. 212–232. https://doi.org/10.5201/ipol.2016.153\n",
        "\n",
        "The algorithms are implemented in Python as a result of a translation from the original C++ code released by the author.\n",
        "The repository used here contains a dataset with images and the ground truth transformations to test the algorithms, as the ones available in the online demo on IPOL: https://ipolcore.ipol.im/demo/clientApp/demo.html?id=153\n",
        "This enable users of this notebook to check easily the validity of the python implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.Test of algorithms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRBs5fjcNXlp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import os\n",
        "import sys\n",
        "import skimage as ski\n",
        "\n",
        "print(os.getcwd())\n",
        "sys.path.append(os.path.abspath(\"../src/\"))\n",
        "from inverse_compositional_algorithm import inverse_compositional_algorithm, robust_inverse_compositional_algorithm, pyramidal_inverse_compositional_algorithm\n",
        "import configuration_handler as cfh\n",
        "import image_optimisation as io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparation of the configuration file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-2Tnf4LNiCU"
      },
      "source": [
        "We create a configuration file with the meta parameters for the algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQlCrZvHNuzG",
        "outputId": "441afb28-d53c-48d1-b496-0e8c928c3931"
      },
      "outputs": [],
      "source": [
        "# cfh.create_config_file(\"config.ini\")\n",
        "# reading the parameters from the configuration file\n",
        "params = cfh.read_config_file(\"config.ini\")\n",
        "params_ica = params[\"inverse_compositional_algorithm\"]\n",
        "params_rica = params[\"robust_inverse_compositional_algorithm\"]\n",
        "params_pica = params[\"pyramidal_inverse_compositional_algorithm\"]\n",
        "\n",
        "# define a dict with image filename and transformation ground truth\n",
        "\n",
        "# calling the pipeline\n",
        "# output_img, debug_dict = process(pic_root, options, params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparation of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import transformation as tf\n",
        "import numpy as np\n",
        "import os.path as path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# A dataset with simple transformations for unit testing\n",
        "dataset_tu = {\n",
        "    \"rubber_whale_tr\": {\n",
        "        \"filename\": \"rubber_whale.png\",\n",
        "        \"transformation_type\": tf.TransformType.TRANSLATION,\n",
        "        \"gt\": [10, 5] # [tx,ty]\n",
        "    },\n",
        "    \"rubber_whale_rt\": {\n",
        "        \"filename\": \"rubber_whale.png\",\n",
        "        \"transformation_type\": tf.TransformType.EUCLIDEAN,\n",
        "        \"gt\": [0., 0., -0.1] # [tx,ty,theta] -> ROTATION, theta in radians and counterclockwise\n",
        "    },\n",
        "    \"rubber_whale_eu\": {\n",
        "        \"filename\": \"rubber_whale.png\",\n",
        "        \"transformation_type\": tf.TransformType.EUCLIDEAN,\n",
        "        \"gt\": [10., 5., -0.1] # [tx,ty,theta] -> ROTATION, theta in radians and counterclockwise\n",
        "    },\n",
        "    \"rubber_whale_zo\": {\n",
        "        \"filename\": \"rubber_whale.png\",\n",
        "        \"transformation_type\": tf.TransformType.SIMILARITY,\n",
        "        \"gt\": [0., 0., -0.1, 0.] # [tx,ty,a,b] -> ZOOM\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"The current directory is: \", os.getcwd())\n",
        "image_path = os.path.join(os.getcwd(), \"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# transform the images and show them\n",
        "fig, axs = plt.subplots(4, 3, figsize=(10,10))\n",
        "fig.suptitle(\"Dataset TU images\")\n",
        "i = 0\n",
        "for sample_key, sample in dataset_tu.items():\n",
        "    print(\"Dataset image: \", sample_key)\n",
        "    print(\"\\tFilename: \", sample[\"filename\"])\n",
        "    original_image = imageio.imread(path.join(image_path, sample[\"filename\"]))\n",
        "    sample[\"original_image\"] = original_image\n",
        "    transformation_type = sample[\"transformation_type\"]\n",
        "    gt = sample[\"gt\"]\n",
        "    # we transform the source image to the target image according to the ground truth\n",
        "    transformed_image = tf.transform_image(original_image, transformation_type, gt)\n",
        "    ofilename = sample_key + \".png\"\n",
        "    print(\"Saving transformed image to file {} in directory {}\".format(ofilename, image_path))\n",
        "    imageio.imwrite(\n",
        "            path.join(image_path, ofilename), \n",
        "            ski.img_as_ubyte(ski.exposure.rescale_intensity(transformed_image))\n",
        "            )\n",
        "    # print(\"\\tType of transformed image: \", transformed_image.dtype)\n",
        "    # To avoid too many errors with image black borders, we swith the reference image to the transformed image\n",
        "    sample[\"original_image\"] = transformed_image\n",
        "    sample[\"transformed_image\"] = original_image\n",
        "    # In that case, the gt transform from transformed to original is the inverse of the gt\n",
        "    gti=tf.matrix2params(np.linalg.inv(tf.params2matrix(gt, transformation_type)), transformation_type)\n",
        "    sample[\"gt\"] = gti\n",
        "    # display the image\n",
        "    axs[i][0].imshow(ski.exposure.rescale_intensity(sample[\"original_image\"]))\n",
        "    axs[i][0].set_title(\"Original image\")\n",
        "    # axs[i][1].imshow(source_image)\n",
        "    # axs[i][1].set_title(\"Source image\")\n",
        "    axs[i][1].imshow(ski.exposure.rescale_intensity(sample[\"transformed_image\"]))\n",
        "    axs[i][1].set_title(\"Transformed image\")\n",
        "    Iw = tf.transform_image(sample[\"transformed_image\"], transformation_type, gt)\n",
        "    axs[i][2].imshow(ski.exposure.rescale_intensity(Iw))\n",
        "    i += 1\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Update**:\n",
        "The authors of the original software and of the online demo, provide the gt transformation from the source image to the transformed image. But the source image is already transformed compared to the original image. I have not been able to recover the transformation from the original to the source and from the source to the transformed.\n",
        "\n",
        "So for my test, I will use the original image as the source, transformed with the given gt given in the online demo. Inputs are then different from the online demo, but the matter is to verify the correctness of the gt computation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test of the algorithm \"Inverse compositional\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"------ Inverse Compositional Algorithm for a translation ------\")\n",
        "fig, axs = plt.subplots(1, 4, figsize=(15,15))\n",
        "fig.suptitle(\"Source, Transformed and Difference images\")\n",
        "i = 0\n",
        "sample = dataset_tu[\"rubber_whale_tr\"]\n",
        "sample_key = \"rubber_whale_tr\"\n",
        "    \n",
        "print(\"Processing dataset image: \", sample_key)\n",
        "original_image = sample[\"original_image\"]\n",
        "transformation_type = sample[\"transformation_type\"]\n",
        "p = np.zeros(transformation_type.nparams())\n",
        "gt = sample[\"gt\"]\n",
        "# we generate the source image according to the ground truth\n",
        "# source_image = generate_source_image(original_image, transformation_type, gt)\n",
        "# we transform the source image to the target image according to the ground truth\n",
        "transformed_image = sample[\"transformed_image\"]\n",
        "# p, error, DI, Iw = inverse_compositional_algorithm(\n",
        "#             original_image, transformed_image, p, transformation_type, params_ica[\"TOL\"], params_ica[\"verbose\"]\n",
        "#         )\n",
        "print(\"With Meta parameters: \", params_ica)\n",
        "print(\"For transformation type: \", transformation_type)\n",
        "p, error, DI, Iw = inverse_compositional_algorithm(\n",
        "                original_image,\n",
        "                transformed_image,\n",
        "                p,\n",
        "                transformation_type, \n",
        "                True, 10, \n",
        "                params_ica[\"TOL\"], \n",
        "                True)\n",
        "# p, error, DI, Iw = pyramidal_inverse_compositional_algorithm(\n",
        "#     original_image,\n",
        "#     transformed_image,\n",
        "#     p,\n",
        "#     transformation_type, \n",
        "#     params_pica[\"pyramid_levels\"], \n",
        "#     params_pica[\"nu\"],\n",
        "#     params_pica[\"TOL\"],\n",
        "#     io.RobustErrorFunctionType.QUADRATIC, \n",
        "#     0,  \n",
        "#     params_pica[\"verbose\"]\n",
        "# )\n",
        "# display the image\n",
        "axs[0].imshow(ski.exposure.rescale_intensity(original_image))\n",
        "axs[0].set_title(\"Original image\")\n",
        "# axs[i][1].imshow(source_image)\n",
        "# axs[i][1].set_title(\"Source image\")\n",
        "axs[1].imshow(ski.exposure.rescale_intensity(transformed_image))\n",
        "axs[1].set_title(\"Transformed image\")\n",
        "# img = axs[i][2].imshow(DI, cmap=\"gray\", vmin=0, vmax=np.max(np.max(DI)))\n",
        "# fig.colorbar(img, ax=axs[i][2])\n",
        "axs[2].imshow(ski.exposure.rescale_intensity(np.nan_to_num(DI, copy=True)))\n",
        "axs[2].set_title(\"Difference image\")\n",
        "axs[3].imshow(ski.exposure.rescale_intensity(np.nan_to_num(Iw, copy=True)))\n",
        "axs[3].set_title(\"Warped image\")\n",
        "\n",
        "print(\"Original parameters: \", gt)\n",
        "print(\"Estimated parameters: \", p)\n",
        "print(\"Error on estimati \", error)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"------ Inverse Compositional Algorithm for a rotation ------\")\n",
        "fig, axs = plt.subplots(1, 4, figsize=(15,15))\n",
        "fig.suptitle(\"Source, Transformed and Difference images for a rotation\")\n",
        "i = 0\n",
        "sample = dataset_tu[\"rubber_whale_rt\"]\n",
        "sample_key = \"rubber_whale_rt\"\n",
        "    \n",
        "print(\"Processing dataset image: \", sample_key)\n",
        "original_image = sample[\"original_image\"]\n",
        "transformation_type = sample[\"transformation_type\"]\n",
        "p = np.zeros(transformation_type.nparams())\n",
        "gt = sample[\"gt\"]\n",
        "# we generate the source image according to the ground truth\n",
        "# source_image = generate_source_image(original_image, transformation_type, gt)\n",
        "# we transform the source image to the target image according to the ground truth\n",
        "transformed_image = sample[\"transformed_image\"]\n",
        "# p, error, DI, Iw = inverse_compositional_algorithm(\n",
        "#             original_image, transformed_image, p, transformation_type, params_ica[\"TOL\"], params_ica[\"verbose\"]\n",
        "#         )\n",
        "print(\"With Meta parameters: \", params_ica)\n",
        "print(\"For transformation type: \", transformation_type)\n",
        "p, error, DI, Iw = inverse_compositional_algorithm(\n",
        "                original_image,\n",
        "                transformed_image,\n",
        "                p,\n",
        "                transformation_type, \n",
        "                True, 10, \n",
        "                params_ica[\"TOL\"], \n",
        "                True)\n",
        "# p, error, DI, Iw = pyramidal_inverse_compositional_algorithm(\n",
        "#     original_image,\n",
        "#     transformed_image,\n",
        "#     p,\n",
        "#     transformation_type, \n",
        "#     params_pica[\"pyramid_levels\"], \n",
        "#     params_pica[\"nu\"],\n",
        "#     params_pica[\"TOL\"],\n",
        "#     io.RobustErrorFunctionType.QUADRATIC, \n",
        "#     0,  \n",
        "#     params_pica[\"verbose\"]\n",
        "# )\n",
        "# display the image\n",
        "axs[0].imshow(ski.exposure.rescale_intensity(original_image))\n",
        "axs[0].set_title(\"Original image\")\n",
        "# axs[i][1].imshow(source_image)\n",
        "# axs[i][1].set_title(\"Source image\")\n",
        "axs[1].imshow(ski.exposure.rescale_intensity(transformed_image))\n",
        "axs[1].set_title(\"Transformed image\")\n",
        "# img = axs[i][2].imshow(DI, cmap=\"gray\", vmin=0, vmax=np.max(np.max(DI)))\n",
        "# fig.colorbar(img, ax=axs[i][2])\n",
        "axs[2].imshow(ski.exposure.rescale_intensity(np.nan_to_num(DI, copy=True)))\n",
        "axs[2].set_title(\"Difference image\")\n",
        "axs[3].imshow(ski.exposure.rescale_intensity(np.nan_to_num(Iw, copy=True)))\n",
        "axs[3].set_title(\"Warped image\")\n",
        "\n",
        "print(\"Original parameters: \", gt)\n",
        "print(\"Estimated parameters: \", p)\n",
        "print(\"Error on estimati \", error)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(\"------ Inverse Compositional Algorithm on dataset_tu ------\")\n",
        "# fig, axs = plt.subplots(5, 4, figsize=(15,15))\n",
        "# fig.suptitle(\"Source, Transformed and Difference images\")\n",
        "# i = 0\n",
        "# for sample_key, sample in dataset_tu.items():\n",
        "#     print(\"Processing dataset image: \", sample_key)\n",
        "#     original_image = sample[\"original_image\"]\n",
        "#     transformation_type = sample[\"transformation_type\"]\n",
        "#     p = np.zeros(transformation_type.nparams())\n",
        "#     gt = sample[\"gt\"]\n",
        "#     # we generate the source image according to the ground truth\n",
        "#     # source_image = generate_source_image(original_image, transformation_type, gt)\n",
        "#     # we transform the source image to the target image according to the ground truth\n",
        "#     transformed_image = sample[\"transformed_image\"]\n",
        "#     # p, error, DI, Iw = inverse_compositional_algorithm(\n",
        "#     #             original_image, transformed_image, p, transformation_type, params_ica[\"TOL\"], params_ica[\"verbose\"]\n",
        "#     #         )\n",
        "#     print(\"With Meta parameters: \", params_pica)\n",
        "#     print(\"For transformation type: \", transformation_type)\n",
        "#     p, error, DI, Iw = pyramidal_inverse_compositional_algorithm(\n",
        "#         original_image,\n",
        "#         transformed_image,\n",
        "#         p,\n",
        "#         transformation_type, \n",
        "#         params_pica[\"pyramid_levels\"], \n",
        "#         params_pica[\"nu\"],\n",
        "#         params_pica[\"TOL\"],\n",
        "#         io.RobustErrorFunctionType.QUADRATIC, \n",
        "#         0,  \n",
        "#         params_pica[\"verbose\"]\n",
        "#     )\n",
        "#     # display the image\n",
        "#     axs[i][0].imshow(ski.exposure.rescale_intensity(original_image))\n",
        "#     axs[i][0].set_title(\"Original image\")\n",
        "#     # axs[i][1].imshow(source_image)\n",
        "#     # axs[i][1].set_title(\"Source image\")\n",
        "#     axs[i][1].imshow(ski.exposure.rescale_intensity(transformed_image))\n",
        "#     axs[i][1].set_title(\"Transformed image\")\n",
        "#     # img = axs[i][2].imshow(DI, cmap=\"gray\", vmin=0, vmax=np.max(np.max(DI)))\n",
        "#     # fig.colorbar(img, ax=axs[i][2])\n",
        "#     axs[i][2].imshow(ski.exposure.rescale_intensity(DI))\n",
        "#     axs[i][2].set_title(\"Difference image\")\n",
        "#     axs[i][3].imshow(ski.exposure.rescale_intensity(Iw))\n",
        "#     axs[i][3].set_title(\"Warped image\")\n",
        "#     i += 1\n",
        "#     print(\"Original parameters: \", gt)\n",
        "#     print(\"Estimated parameters: \", p)\n",
        "#     print(\"Error on estimation: \", error)\n",
        "\n",
        "# plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
