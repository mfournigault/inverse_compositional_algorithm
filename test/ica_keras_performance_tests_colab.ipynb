{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import affine_transform\n",
    "import skimage as ski\n",
    "import time\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src/\"))\n",
    "sys.path.append(os.path.abspath(\"../src/keras-tf\"))\n",
    "\n",
    "import configuration_handler as cfh\n",
    "import image_optimisation as io\n",
    "import transformation as tr\n",
    "import tf_inverse_compositional_algorithm as tf_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a configuration file with the meta parameters for the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the parameters from the configuration file\n",
    "params = cfh.read_config_file(\"config.ini\")\n",
    "params_rica = params[\"robust_inverse_compositional_algorithm\"]\n",
    "params_pica = params[\"pyramidal_inverse_compositional_algorithm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing evaluation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.ops.image import affine_transform\n",
    "from transformation import TransformType\n",
    "from tf_transformation import pad_params\n",
    "from tf_inverse_compositional_algorithm import PyramidalInverseCompositional\n",
    "from image_optimisation import RobustErrorFunctionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFDSEvaluator:\n",
    "    def __init__(self, img_size=(256, 256)):\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = 4\n",
    "        self.models = {\n",
    "            'Pyramidal-tr': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.TRANSLATION,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            ),\n",
    "            'Pyramidal-eu': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.EUCLIDEAN,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            ),\n",
    "            'Pyramidal-si': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.SIMILARITY,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            ),\n",
    "            'Pyramidal-af': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.AFFINITY,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            ),\n",
    "            'Pyramidal-ho': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.HOMOGRAPHY,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # For a local use: Stop magic stuff that eats up all the memory\n",
    "        # Could be disabled if you have enough memory\n",
    "        self.data_options = tf.data.Options()\n",
    "        self.data_options.autotune.enabled = False\n",
    "        self.data_options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "        self.data_options.experimental_optimization.inject_prefetch = False\n",
    "        # Load and prepare the source dataset\n",
    "        self.im1_ds, self.im1_ds_info = self.load_prepare_source_dataset()\n",
    "        print(self.im1_ds_info)\n",
    "        print(\"number of images in the dataset:\", self.im1_ds.cardinality())\n",
    "\n",
    "    def load_prepare_source_dataset(self):\n",
    "        \"\"\"Load imagenette dataset from TFDS, a small subset of ImageNet\"\"\"\n",
    "        im1_ds, info = tfds.load('imagenette', with_info=True, split=\"train[:5%]\", shuffle_files=True)\n",
    "        # prepare im1_ds\n",
    "        # As we don't use the images for classification, we only keep the images\n",
    "        im1_ds = im1_ds.map(lambda x: x[\"image\"])\n",
    "        # For a local use: Stop magic stuff that eats up all the memory\n",
    "        # Could be disabled if you have enough memory\n",
    "        im1_ds = im1_ds.with_options(self.data_options)\n",
    "\n",
    "        # Images do not have the same size, so we resize them before batching\n",
    "        im1_ds = im1_ds.map(lambda x: tf.image.resize(x, self.img_size))\n",
    "        im1_ds = im1_ds.batch(self.batch_size).map(lambda x: tf.image.convert_image_dtype(x, tf.float32))\n",
    "        # im1_ds = im1_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "        im1_ds = im1_ds.prefetch(tf.data.AUTOTUNE) # the dataset is huge, so we don't cache it\n",
    "        return im1_ds, info        \n",
    "\n",
    "    def prepare_datasets(self, im1_ds, transform_type):\n",
    "        # duplicate the image dataset to apply transformation and constitute a second ds\n",
    "        arr = list(im1_ds.unbatch().as_numpy_iterator())\n",
    "        im2_ds = tf.data.Dataset.from_tensor_slices(arr)\n",
    "        # For a local use: Stop magic stuff that eats up all the memory\n",
    "        # Could be disabled if you have enough memory\n",
    "        im2_ds = im2_ds.with_options(self.data_options)\n",
    "         \n",
    "\n",
    "        # prepare the dataset of affine transformations\n",
    "        p_ds = tf.data.Dataset.from_generator(\n",
    "            lambda: (self.generate_params(transform_type) for _ in range(len(arr))),\n",
    "            output_signature=tf.TensorSpec(shape=(8,), dtype=tf.float32)\n",
    "        )\n",
    "        # p_ds = p_ds.batch(self.batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "        p_ds = p_ds.batch(self.batch_size).prefetch(tf.data.AUTOTUNE) # the dataset is huge, so we don't cache it\n",
    "\n",
    "        # prepare im2_ds\n",
    "        im2_ds = im2_ds.batch(self.batch_size).map(lambda x: tf.image.resize(x, self.img_size))\n",
    "        im2_ds = im2_ds.map(lambda x: tf.image.convert_image_dtype(x, tf.float32))\n",
    "        combined_ds = tf.data.Dataset.zip((im2_ds, p_ds))\n",
    "        transformed_ds = combined_ds.map(\n",
    "            lambda im, p: affine_transform(\n",
    "                im, p, \n",
    "                interpolation=\"bilinear\", \n",
    "                fill_mode=\"constant\", \n",
    "                fill_value=np.nan, \n",
    "                data_format=\"channels_last\"\n",
    "            ),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "        # im2_ds = transformed_ds.cache().batch(self.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        im2_ds = transformed_ds.prefetch(tf.data.AUTOTUNE) # the dataset is huge, so we don't cache it\n",
    "\n",
    "        return im2_ds, p_ds\n",
    "\n",
    "\n",
    "    def generate_affine_params(self):\n",
    "        \"\"\"Generate random affine transformation parameters\"\"\"\n",
    "        return {\n",
    "            \"scale\": np.random.uniform(0.1, 0.3, 2),\n",
    "            \"rotation\": np.random.uniform(-np.pi/6, np.pi/6),\n",
    "            \"shear\": np.random.uniform(-0.3, 0.3, 2),\n",
    "            \"translation\": np.random.uniform(-30, 30, 2),\n",
    "            \"homography\": np.random.uniform(0., 0.2, 2)\n",
    "        }\n",
    "    \n",
    "    def generate_params(self, transform_type: TransformType):\n",
    "        aff_params = self.generate_affine_params()\n",
    "        match transform_type:\n",
    "            case TransformType.TRANSLATION:\n",
    "                p = aff_params['translation']\n",
    "                return pad_params(p, 8)\n",
    "            case TransformType.EUCLIDEAN:\n",
    "                p = np.array([aff_params['translation'], aff_params['rotation']])\n",
    "                return pad_params(p, 8)\n",
    "            case TransformType.SIMILARITY: # specified as (tx, ty, s, sh)\n",
    "                p = np.array([aff_params['translation'], aff_params['scale'][0], aff_params['shear'][0]])\n",
    "                return pad_params(p, 8)\n",
    "            case TransformType.AFFINITY: # specified as (tx, ty, a00, a01, a10, a11)\n",
    "                p = np.array([aff_params['translation'], aff_params['scale'][0], aff_params['shear'], aff_params['scale'][1]])\n",
    "                return pad_params(p, 8)\n",
    "            case TransformType.HOMOGRAPHY: # specified as (tx, ty, a00, a01, a10, a11, a20, a21)\n",
    "                p = np.array([aff_params['translation'], aff_params['scale'][0], aff_params['shear'], aff_params['scale'][1], \n",
    "                              aff_params['homography']])\n",
    "                return tf.constant(p)\n",
    "\n",
    "    def evaluate(self, num_samples=50):\n",
    "        # results = {name: {'mse': [], 'mae': [], 'epe': [], 'time': []} \n",
    "        #           for name in self.models}\n",
    "        results = {name: {'mse': [], 'mae': [], 'time': []} \n",
    "                  for name in self.models}\n",
    "        nb_batches = self.im1_ds.cardinality().numpy() // self.batch_size\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "            # Prepare datasets\n",
    "            tf.print(\"Preparing datasets for model\", model_name)\n",
    "            im2_ds, p_ds = self.prepare_datasets(self.im1_ds, model.transform_type)\n",
    "\n",
    "            i = 0\n",
    "            for batch_im1, batch_im2, batch_params in zip(self.im1_ds, im2_ds, p_ds):\n",
    "                tf.print(\"Processing batch number\", i, \" on \", nb_batches)\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Estimate transformation\n",
    "                p_pred, error, DI, Iw = model([batch_im1, batch_im2])\n",
    "                params_pred = p_pred[0]\n",
    "                true_params = batch_params.numpy()[0]\n",
    "                \n",
    "                # Calculate parameter errors\n",
    "                mse = np.mean((params_pred - true_params)**2)\n",
    "                mae = np.mean(np.abs(params_pred - true_params))\n",
    "                \n",
    "                # # Calculate endpoint error (EPE)\n",
    "                # pred_flow = self.params_to_flow(params_pred)\n",
    "                # true_flow = self.params_to_flow(true_params)\n",
    "                # epe = np.mean(np.sqrt(np.sum((pred_flow - true_flow)**2, axis=-1)))\n",
    "                \n",
    "                # Store results\n",
    "                results[name]['mse'].append(mse)\n",
    "                results[name]['mae'].append(mae)\n",
    "                # results[name]['epe'].append(epe)\n",
    "                results[name]['time'].append(time.time() - start_time)\n",
    "                i += 1\n",
    "                \n",
    "        return results\n",
    "\n",
    "    def params_to_flow(self, params):\n",
    "        \"\"\"Convert affine parameters to flow field\"\"\"\n",
    "        h, w = self.img_size\n",
    "        matrix = params.reshape(3, 3)\n",
    "        \n",
    "        x = np.linspace(0, w-1, w)\n",
    "        y = np.linspace(0, h-1, h)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        ones = np.ones_like(xx)\n",
    "        coords = np.stack([xx, yy, ones], axis=0)\n",
    "        \n",
    "        transformed = np.tensordot(matrix, coords, axes=([1], [0]))\n",
    "        flow = np.moveaxis(transformed, 0, -1) - np.stack([xx, yy], axis=-1)\n",
    "        return flow\n",
    "\n",
    "    def plot_results(self, results):\n",
    "        metrics = ['mse', 'mae', 'epe', 'time']\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            ax = axs[i//2, i%2]\n",
    "            for name in self.models:\n",
    "                ax.plot(results[name][metric], label=name)\n",
    "            ax.set_title(f'{metric.upper()} Comparison')\n",
    "            ax.set_xlabel('Sample Index')\n",
    "            ax.set_ylabel(metric.upper())\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='imagenette',\n",
      "    full_name='imagenette/full-size-v2/1.0.0',\n",
      "    description=\"\"\"\n",
      "    Imagenette is a subset of 10 easily classified classes from the Imagenet\n",
      "    dataset. It was originally prepared by Jeremy Howard of FastAI. The objective\n",
      "    behind putting together a small version of the Imagenet dataset was mainly\n",
      "    because running new ideas/algorithms/experiments on the whole Imagenet take a\n",
      "    lot of time.\n",
      "    \n",
      "    This version of the dataset allows researchers/practitioners to quickly try out\n",
      "    ideas and share with others. The dataset comes in three variants:\n",
      "    \n",
      "    *   Full size\n",
      "    *   320 px\n",
      "    *   160 px\n",
      "    \n",
      "    Note: The v2 config correspond to the new 70/30 train/valid split (released in\n",
      "    Dec 6 2019).\n",
      "    \"\"\",\n",
      "    config_description=\"\"\"\n",
      "    full-size variant.\n",
      "    \"\"\",\n",
      "    homepage='https://github.com/fastai/imagenette',\n",
      "    data_dir='/home/mike/tensorflow_datasets/imagenette/full-size-v2/1.0.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=Unknown size,\n",
      "    dataset_size=1.46 GiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=9469, num_shards=16>,\n",
      "        'validation': <SplitInfo num_examples=3925, num_shards=4>,\n",
      "    },\n",
      "    citation=\"\"\"@misc{imagenette,\n",
      "      author    = \"Jeremy Howard\",\n",
      "      title     = \"imagenette\",\n",
      "      url       = \"https://github.com/fastai/imagenette/\"\n",
      "    }\"\"\",\n",
      ")\n",
      "number of images in the dataset: tf.Tensor(119, shape=(), dtype=int64)\n",
      "Preparing datasets for model Pyramidal-tr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 17:35:01.841226: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-03-11 17:35:30.193463: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: paddings must be a matrix with 2 columns: [1]\n",
      "2025-03-11 17:35:30.206813: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: InvalidArgumentError: {{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [2] != values[1].shape = [] [Op:Pack] name: \n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/tmp/ipykernel_46229/3981852581.py\", line 102, in <genexpr>\n",
      "    lambda: (self.generate_params(transform_type) for _ in range(len(arr))),\n",
      "\n",
      "  File \"/tmp/ipykernel_46229/3981852581.py\", line 143, in generate_params\n",
      "    return pad_params(p, 8)\n",
      "\n",
      "  File \"/mnt/c/Users/mikef/git/inverse_compositional_algorithm/src/keras-tf/tf_transformation.py\", line 31, in pad_params\n",
      "    return tf.cond(\n",
      "\n",
      "  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "\n",
      "  File \"/mnt/c/Users/mikef/git/inverse_compositional_algorithm/src/keras-tf/tf_transformation.py\", line 33, in <lambda>\n",
      "    lambda: tf.pad(params, [[0, pad_length]]),\n",
      "\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pack_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} Shapes of all inputs must match: values[0].shape = [2] != values[1].shape = [] [Op:Pack] name: \n",
      "\n",
      "\n",
      "2025-03-11 17:35:30.207257: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: InvalidArgumentError: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} paddings must be a matrix with 2 columns: [1] [Op:Pad]\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "\n",
      "  File \"/tmp/ipykernel_46229/3981852581.py\", line 102, in <genexpr>\n",
      "    lambda: (self.generate_params(transform_type) for _ in range(len(arr))),\n",
      "\n",
      "  File \"/tmp/ipykernel_46229/3981852581.py\", line 143, in generate_params\n",
      "    return pad_params(p, 8)\n",
      "\n",
      "  File \"/mnt/c/Users/mikef/git/inverse_compositional_algorithm/src/keras-tf/tf_transformation.py\", line 31, in pad_params\n",
      "    return tf.cond(\n",
      "\n",
      "  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "\n",
      "  File \"/mnt/c/Users/mikef/git/inverse_compositional_algorithm/src/keras-tf/tf_transformation.py\", line 33, in <lambda>\n",
      "    lambda: tf.pad(params, [[0, pad_length]]),\n",
      "\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} paddings must be a matrix with 2 columns: [1] [Op:Pad]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} InvalidArgumentError: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} paddings must be a matrix with 2 columns: [1] [Op:Pad]\nTraceback (most recent call last):\n\n  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n\n  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_46229/3981852581.py\", line 102, in <genexpr>\n    lambda: (self.generate_params(transform_type) for _ in range(len(arr))),\n\n  File \"/tmp/ipykernel_46229/3981852581.py\", line 143, in generate_params\n    return pad_params(p, 8)\n\n  File \"/mnt/c/Users/mikef/git/inverse_compositional_algorithm/src/keras-tf/tf_transformation.py\", line 31, in pad_params\n    return tf.cond(\n\n  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/mnt/c/Users/mikef/git/inverse_compositional_algorithm/src/keras-tf/tf_transformation.py\", line 33, in <lambda>\n    lambda: tf.pad(params, [[0, pad_length]]),\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} paddings must be a matrix with 2 columns: [1] [Op:Pad]\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m TFDSEvaluator()\n\u001b[0;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mplot_results(results)\n",
      "Cell \u001b[0;32mIn[11], line 171\u001b[0m, in \u001b[0;36mTFDSEvaluator.evaluate\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m    168\u001b[0m im2_ds, p_ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_datasets(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim1_ds, model\u001b[38;5;241m.\u001b[39mtransform_type)\n\u001b[1;32m    170\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_im1, batch_im2, batch_params \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim1_ds, im2_ds, p_ds):\n\u001b[1;32m    172\u001b[0m     tf\u001b[38;5;241m.\u001b[39mprint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing batch number\u001b[39m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m on \u001b[39m\u001b[38;5;124m\"\u001b[39m, nb_batches)\n\u001b[1;32m    173\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3086\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3084\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3085\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3086\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3088\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mUnknownError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} InvalidArgumentError: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} paddings must be a matrix with 2 columns: [1] [Op:Pad]\nTraceback (most recent call last):\n\n  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n\n  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/tmp/ipykernel_46229/3981852581.py\", line 102, in <genexpr>\n    lambda: (self.generate_params(transform_type) for _ in range(len(arr))),\n\n  File \"/tmp/ipykernel_46229/3981852581.py\", line 143, in generate_params\n    return pad_params(p, 8)\n\n  File \"/mnt/c/Users/mikef/git/inverse_compositional_algorithm/src/keras-tf/tf_transformation.py\", line 31, in pad_params\n    return tf.cond(\n\n  File \"/home/mike/miniconda3/envs/tensorflow2/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n\n  File \"/mnt/c/Users/mikef/git/inverse_compositional_algorithm/src/keras-tf/tf_transformation.py\", line 33, in <lambda>\n    lambda: tf.pad(params, [[0, pad_length]]),\n\ntensorflow.python.framework.errors_impl.InvalidArgumentError: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:GPU:0}} paddings must be a matrix with 2 columns: [1] [Op:Pad]\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "evaluator = TFDSEvaluator()\n",
    "results = evaluator.evaluate(num_samples=50)\n",
    "evaluator.plot_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics\n",
    "print(\"Average Metrics:\")\n",
    "for name in evaluator.models:\n",
    "    print(f\"\\n{name}:\")\n",
    "    for metric in ['mse', 'mae', 'epe', 'time']:\n",
    "        avg = np.mean(results[name][metric])\n",
    "        print(f\"  {metric.upper()}: {avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
