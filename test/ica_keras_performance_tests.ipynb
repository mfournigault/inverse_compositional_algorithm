{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import affine_transform\n",
    "import skimage as ski\n",
    "import time\n",
    "import imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../src/\"))\n",
    "sys.path.append(os.path.abspath(\"../src/keras-tf\"))\n",
    "\n",
    "import configuration_handler as cfh\n",
    "import image_optimisation as io\n",
    "import transformation as tr\n",
    "import tf_inverse_compositional_algorithm as tf_ica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a configuration file with the meta parameters for the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the parameters from the configuration file\n",
    "params = cfh.read_config_file(\"config.ini\")\n",
    "params_rica = params[\"robust_inverse_compositional_algorithm\"]\n",
    "params_pica = params[\"pyramidal_inverse_compositional_algorithm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing evaluation tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.ops.image import affine_transform\n",
    "from transformation import TransformType\n",
    "from tf_inverse_compositional_algorithm import PyramidalInverseCompositional\n",
    "from image_optimisation import RobustErrorFunctionType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFDSEvaluator:\n",
    "    def __init__(self, img_size=(256, 256)):\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = 32\n",
    "        self.models = {\n",
    "            'Pyramidal-tr': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.TRANSLATION,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            ),\n",
    "            'Pyramidal-eu': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.EUCLIDEAN,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            ),\n",
    "            'Pyramidal-si': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.SIMILARITY,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            ),\n",
    "            'Pyramidal-af': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.AFFINITY,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            ),\n",
    "            'Pyramidal-ho': PyramidalInverseCompositional(\n",
    "                transform_type=TransformType.HOMOGRAPHY,\n",
    "                nscales=3,\n",
    "                nu=0.5,\n",
    "                TOL=1e-5,\n",
    "                robust_type=RobustErrorFunctionType.CHARBONNIER,\n",
    "                lambda_=0.,\n",
    "                nanifoutside=True,\n",
    "                delta=10,\n",
    "                verbose=False\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # Load and prepare the source dataset\n",
    "        self.im1_ds = self.load_prepare_source_dataset()\n",
    "\n",
    "    def load_prepare_source_dataset(self):\n",
    "        \"\"\"Load imagenette dataset from TFDS, a small subset of ImageNet\"\"\"\n",
    "        im1_ds = tfds.load('imagenette', split='test', shuffle_files=True)\n",
    "        # prepare im1_ds\n",
    "        im1_ds = im1_ds.batch(self.batch_size).map(lambda x: tf.image.resize(x[\"image\"], self.img_size))\n",
    "        im1_ds = im1_ds.map(lambda x: tf.image.convert_image_dtype(x, tf.float32))\n",
    "        im1_ds = im1_ds.cache().prefetch(tf.data.AUTOTUNE)\n",
    "        return im1_ds        \n",
    "\n",
    "    def prepare_datasets(self, im1_ds, transform_type):\n",
    "        # duplicate the image dataset to apply transformation and constitute a second ds\n",
    "        arr = list(im1_ds.as_numpy_iterator())\n",
    "        im2_ds = tf.data.Dataset.from_tensor_slices(arr)\n",
    "\n",
    "\n",
    "        # prepare the dataset of affine transformations\n",
    "        p_ds = tf.dataset.from_generator(\n",
    "            lambda: (self.generate_params(transform_type) for _ in range(len(arr))),\n",
    "            output_signature=tf.TensorSpec(shape=(8,), dtype=tf.float32)\n",
    "        )\n",
    "        p_ds = p_ds.batch(self.batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        # prepare im2_ds\n",
    "        im2_ds = im2_ds.batch(self.batch_size).map(lambda x: tf.image.resize(x[\"image\"], self.img_size))\n",
    "        im2_ds = im2_ds.map(lambda x: tf.image.convert_image_dtype(x, tf.float32))\n",
    "        combined_ds = tf.data.Dataset.zip((im2_ds, p_ds))\n",
    "        transformed_ds = combined_ds.map(\n",
    "            lambda im, p: affine_transform(\n",
    "                im, p, \n",
    "                interpolation=\"bilinear\", \n",
    "                fill_mode=\"constant\", \n",
    "                fill_value=np.nan, \n",
    "                data_format=\"channels_last\"\n",
    "            ),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "        im2_ds = transformed_ds.cache().batch(self.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "        return im2_ds, p_ds\n",
    "\n",
    "\n",
    "    def generate_affine_params(self):\n",
    "        \"\"\"Generate random affine transformation parameters\"\"\"\n",
    "        return {\n",
    "            \"scale\": np.random.uniform(0.1, 0.3, 2),\n",
    "            \"rotation\": np.random.uniform(-np.pi/6, np.pi/6),\n",
    "            \"shear\": np.random.uniform(-0.3, 0.3, 2),\n",
    "            \"translation\": np.random.uniform(-30, 30, 2),\n",
    "            \"homography\": np.random.uniform(0., 0.2, 2)\n",
    "        }\n",
    "    \n",
    "    def generate_params(self, transform_type: TransformType):\n",
    "        aff_params = self.generate_affine_params()\n",
    "        match transform_type:\n",
    "            case TransformType.TRANSLATION:\n",
    "                p = aff_params['translation']\n",
    "                return tf.pad_params(p, 8)\n",
    "            case TransformType.EUCLIDEAN:\n",
    "                p = np.array([aff_params['translation'], aff_params['rotation']])\n",
    "                return tf.pad_params(p, 8)\n",
    "            case TransformType.SIMILARITY: # specified as (tx, ty, s, sh)\n",
    "                p = np.array([aff_params['translation'], aff_params['scale'][0], aff_params['shear'][0]])\n",
    "                return tf.pad_params(p, 8)\n",
    "            case TransformType.AFFINITY: # specified as (tx, ty, a00, a01, a10, a11)\n",
    "                p = np.array([aff_params['translation'], aff_params['scale'][0], aff_params['shear'], aff_params['scale'][1]])\n",
    "                return tf.pad_params(p, 8)\n",
    "            case TransformType.HOMOGRAPHY: # specified as (tx, ty, a00, a01, a10, a11, a20, a21)\n",
    "                p = np.array([aff_params['translation'], aff_params['scale'][0], aff_params['shear'], aff_params['scale'][1], \n",
    "                              aff_params['homography']])\n",
    "                return tf.constant(p)\n",
    "\n",
    "    def evaluate(self, num_samples=50):\n",
    "        # results = {name: {'mse': [], 'mae': [], 'epe': [], 'time': []} \n",
    "        #           for name in self.models}\n",
    "        results = {name: {'mse': [], 'mae': [], 'time': []} \n",
    "                  for name in self.models}\n",
    "        \n",
    "        for model_name, model in self.models.items():\n",
    "           \n",
    "            im2_ds, p_ds = self.prepare_datasets(self.im1_ds, model.transform_type)\n",
    "\n",
    "            for batch_im1, batch_im2, batch_params in zip(im1_ds, im2_ds, p_ds):\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Estimate transformation\n",
    "                p_pred, error, DI, Iw = model([batch_im1, batch_im2])\n",
    "                params_pred = p_pred.numpy()[0]\n",
    "                true_params = batch_params.numpy()[0]\n",
    "                \n",
    "                # Calculate parameter errors\n",
    "                mse = np.mean((params_pred - true_params)**2)\n",
    "                mae = np.mean(np.abs(params_pred - true_params))\n",
    "                \n",
    "                # # Calculate endpoint error (EPE)\n",
    "                # pred_flow = self.params_to_flow(params_pred)\n",
    "                # true_flow = self.params_to_flow(true_params)\n",
    "                # epe = np.mean(np.sqrt(np.sum((pred_flow - true_flow)**2, axis=-1)))\n",
    "                \n",
    "                # Store results\n",
    "                results[name]['mse'].append(mse)\n",
    "                results[name]['mae'].append(mae)\n",
    "                # results[name]['epe'].append(epe)\n",
    "                results[name]['time'].append(time.time() - start_time)\n",
    "                \n",
    "        return results\n",
    "\n",
    "    def params_to_flow(self, params):\n",
    "        \"\"\"Convert affine parameters to flow field\"\"\"\n",
    "        h, w = self.img_size\n",
    "        matrix = params.reshape(3, 3)\n",
    "        \n",
    "        x = np.linspace(0, w-1, w)\n",
    "        y = np.linspace(0, h-1, h)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        ones = np.ones_like(xx)\n",
    "        coords = np.stack([xx, yy, ones], axis=0)\n",
    "        \n",
    "        transformed = np.tensordot(matrix, coords, axes=([1], [0]))\n",
    "        flow = np.moveaxis(transformed, 0, -1) - np.stack([xx, yy], axis=-1)\n",
    "        return flow\n",
    "\n",
    "    def plot_results(self, results):\n",
    "        metrics = ['mse', 'mae', 'epe', 'time']\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            ax = axs[i//2, i%2]\n",
    "            for name in self.models:\n",
    "                ax.plot(results[name][metric], label=name)\n",
    "            ax.set_title(f'{metric.upper()} Comparison')\n",
    "            ax.set_xlabel('Sample Index')\n",
    "            ax.set_ylabel(metric.upper())\n",
    "            ax.legend()\n",
    "            ax.grid(True)\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TFDSEvaluator' object has no attribute 'load_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m \u001b[43mTFDSEvaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mevaluate(num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m      4\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mplot_results(results)\n",
      "Cell \u001b[1;32mIn[14], line 64\u001b[0m, in \u001b[0;36mTFDSEvaluator.__init__\u001b[1;34m(self, img_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPyramidal-tr\u001b[39m\u001b[38;5;124m'\u001b[39m: PyramidalInverseCompositional(\n\u001b[0;32m      7\u001b[0m         transform_type\u001b[38;5;241m=\u001b[39mTransformType\u001b[38;5;241m.\u001b[39mTRANSLATION,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     )\n\u001b[0;32m     61\u001b[0m }\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TFDSEvaluator' object has no attribute 'load_dataset'"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "evaluator = TFDSEvaluator()\n",
    "results = evaluator.evaluate(num_samples=50)\n",
    "evaluator.plot_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics\n",
    "print(\"Average Metrics:\")\n",
    "for name in evaluator.models:\n",
    "    print(f\"\\n{name}:\")\n",
    "    for metric in ['mse', 'mae', 'epe', 'time']:\n",
    "        avg = np.mean(results[name][metric])\n",
    "        print(f\"  {metric.upper()}: {avg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
